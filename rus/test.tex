\documentclass[draft, 12pt]{article}
\usepackage[cp1251]{inputenc} % следующие две строки используются для
\usepackage[english,russian]{babel}   % руссификации AmSLaTeX
\usepackage{amsmath,amsfonts,amssymb,euscript,graphicx,wrapfig,multirow}
\usepackage{dsfont}
\textheight=240mm \textwidth=170mm
\hoffset=-17mm % сдвиг влево
\voffset=-17mm % сдвиг вверх

\begin{document}

\noindent УДК 519.642.2

\begin{center}
\textbf{О механизме оценки вероятностей пересечения блуждающей частицей поглощающего барьера в модели CGMY, основанном на применении нейронных сетей} \\[3mm]

\textbf{О.~Е.~Кудрявцев}\\[2mm]
\emph{Ростовский Филиал РТА}

\textbf{В.~В.~Родоченко}\\[2mm]
\emph{Южный Федеральный Университет}
\end{center}

\begin{abstract}
	Мы предлагаем новый метод вычисления вероятности перехода блуждающей частицы через фиксированный барьер. Рассматривая историю поведения блуждающей частицы во времени, мы строим гистограммы вероятностей распределения пересечений наперёд заданных барьеров, используем исходное предположение наиболее подходящей о модели Леви (конкретно -- модели CGMY), которой подчиняется динамика случайного блуждания и, затем, тренируем искусственную  нейронную сеть для калибровки параметров этой модели. Благодаря тому, что обучение нейронной сети можно проводить однажды, полученный подход (с предварительно обученной сетью) позволяет многократно превзойти традиционные механизмы калибровки в скорости, при этом незначительно уступая в точности. Метод имеет широкий ряд приложений в задачах, возникающих на финансовых рынках -- в особенности если актив является одновременно высоколиквидным и высоковолатильным (например, криптовалюты).
\end{abstract}

Ключевые слова: {нейронные сети, задачи перехода через барьер, процессы Леви, численные методы.}

\section{Введение}

Значительный прогресс, который наблюдается в сферах искусственного интеллекта и машинного обучения, оказывает влияние на методы, которые используются исследователями и инженерами для решения ежедневных задач. Настоящая статья посвящена применению искуственных нейронных сетей для решения одной из классических проблем управления риском -- оценки перехода блуждающей частицы через фиксированный барьер. Мы ограничиваем себя случаем, когда удаётся сделать предположение о наиболее подходящей модели, которой следует поведение частицы, заметив, что выбор такой модели может существенно влиять на выбор подходящего для работы инструмента (см, напр. [Madan]).

Для обеспечения работы финансовых рынков необходимо ежедневное решение весьма значительного количества задач, которые имеют существенную вычислительную сложностью. Среди них -- вычисление торговых индикаторов, цен производных ценных бумаг, определений коэффициентов хеджирования. Для построения эффективной численной реализации методов их решения привлекается аппарат теории вероятностей и современные вычислительные методы. Тем не менее, в частности, методы калибровки моделей со скачками и/или стохастической волатильностью требуют огромных вычислительных мощностей, потому что методы вычисления производных бумаг в этих моделях работают сравнительно медленно, а само вычисление необходимо производить постоянно и многократно (см, напр. [Madan]).

Идея о том, что для ускорения процесса искуственные нейронные сети могут быть эффективно использованы для решения задачи калибровки случайного процесса, описана, в частности, в статье [Horvath]. Основа подхода состоит в следующем. При условии, что модель известна, задачей калибровки является найти оптимальные параметры модели -- в том смысле, что они минимизируют некоторый функционал, понимаемый как разность между вектором цен, генерируемых рынком и вектором цен, предсказываемых моделью. Реализация задачи калибровки делится на два этапа. Сначала мы заменяем существующий, медленный способ калибровки, его приближением в виде метода машинного обучения, и обучаем модель на исторических данных. Затем -- используем получившуюся модель вместо существующего метода и сравниваем их результаты с точки зрения скорости и точности.

Поскольку обучение нейронной сети можно проводить однажды, а затем использовать её для любого набора похожих данных, временем на обучение сети в вычислительных экспериментах пренебрегают (как пренебрегают временем, потраченным на кодирование и подготовку данных в прочих случаях). После обучения скорость решения задач калибровки может увеличиваться на порядки [Horvath, Itkin].

Заметим, что этот подход, хотя и является эффективным, не лишён некоторых принципиальных недостатков, подробно освещённых в [Itkin] и [Huh]. Среди них -- неточность предсказаний при ограниченном наборе тестовых данных, способность генерировать скачкообразные изменения цен в непрерывных моделях, а также необходимость специальным образом учитывать условия безарбитражности.

Целью настоящей статьи является показать его применимость его для калибровки модели CGMY на исходных данных, содержащих историю переходов блуждающей частицы (цены базового актива) через ряд фиксированных барьеров.

\section{Архитектура сети и функция активации}

Искуственные нейронные сети (ИНС) -- это сети из искусственных нейронов [Bishop]. Связи между нейронами моделируются при помощи "весов". Нейрон может принимать на вход некоторое количество сигналов (вектор $x = [x_1, x_2, ... x_{d_0}]$, $x\in R^{d_0}$), которые затем изменяются при помощи весов $\omega_j = [\omega_{i,j}, ... , \omega_{i,m}], \omega_{i,j} \in \mathds{R}^m$, соответствующих (скрытому) слою j, и суммируются как линейная комбинация. К результату применяется функция активации, которая окончательно определяет значение выходного сигнала $o_j = y$, $x\in R^{d_1}$. Если не применять функцию активации -- нейронная сеть сможет решать только задачи линейной регрессии, что ограничит её способность к обучению.

Из практических соображений генерируемые результаты должны принадлежать классу $C^2$. В силу этого соображения, мы ограничимся случаем без циклов, аналогичным рассмотренному в [Itkin]. Для него действует теорема Хорника [Horkik], согласно которой функция активации должна принадлежить этому же классу:

\textbf{Теорема 1.} \textit{ Пусть $\mathcal{N}^{\sigma}_{d_0, d_1}$ -- множество ИНС с функцией активации $\sigma : \mathds{R} \rightarrow \mathds{R}$, c размерностью входного вектора $d_0 \in N$ и выходного вектора $d_1 \in N$. Пусть $F \in C^{n}$ и $F_{ANN}: \mathds{R}^{d_0} \rightarrow \mathds{R}$. Тогда если функция активации $\sigma \in C^n\mathds{(R)}$ и не является константой, то $\mathcal{N}^{\sigma}_{d_0, d_1}$ приближает $F$ и все её производные до порядка $n$. }

Заметим, что разнообразие архитектур нейронных сетей в настоящее время достаточно велико. Обзор наиболее широко применяемых архитектур можно найти в [Osterlee, Huh]. 
В статье [Hochreiter] представлены рекуррентные сети с памятью LSTM, которые успешно применяются для задач регрессии и прогнозирования ценовых рядов -- например, в работе [Kim]. В [Huh] конструируются нейронные сети специального вида для прогнозирования параметров процессов Леви, а также приводится ряд идей для увеличения объёма тренировочной выборки.

Рассмотрим для примера однопараметрическую модель Блэка-Шоулза [12]. В ней предполагается, что волатильность ценной бумаги, $\sigma$, является функцией от $5$ параметров $S, K, T, r, q$ -- которые являются ценой актива, ценой исполнения, временем истечения контракта, безрисковой процентной ставкой и ставкой по дивидендам. Простейшая нейронная сеть, приближающая такую модель имела бы $d_0 = 5$ и $d_1 = 1$ и выполняла бы роль аппроксиматора, действующего $\mathds{R}^5 \rightarrow \mathds{R}^1$. Более точное приближение могло бы включать некоторую историю изменения цены базового актива, что увеличило бы размерность входного вектора.

Благодаря увеличению вычислительных мощностей, во-первых и наличию в открытом доступе библиотек Keras, Tensorflow и др., во-вторых, -- решение многомерных задач такого рода стало достижимым.

\section{Подготовка исходных данных}

\section{Результаты}

\section{Заключение}

%% оформление рисунков
%\begin{figure}[h!]
%\begin{center}
%\includegraphics[width=0.75\textwidth]{Ivanov_Petrov_pic_1.eps}\\
%\emph{Рис. 1. }\end{center}
%\end{figure}
%
%\begin{wrapfigure}{R}{5.0cm}
%\begin{center}
%\includegraphics[width=4.5cm, height=4.5cm]{Ivanov_Petrov_pic_1.eps}\\
%\emph{Рис. 1.}\end{center}
%\end{wrapfigure}
%
%% оформление перечней
%\begin{itemize}
%\setlength{\itemsep}{-1mm}
%  \item
%  \item
%  \item
%\end{itemize}

\bigskip\centerline{\bf Литература}

% 5.	\emph{ Баталов, А.~Л.} Сакральная топография средневекового города / А.~Л.~Баталов, Л.~А.~Беляев // Известия Института христианской культуры средневековья. -- Москва, 1998. -- Т. 1. -- С.~13-22.

% 6.	\emph{ Боголюбов, А.~Н.} О вещественных резонансах в волноводе с неоднородным заполнением / А.~Н.~ Боголюбов, А.~Л.~Делицын, М.~Д.~Малых // Вестник Московского университета. Сер. 3, Физика. Астрономия. -- 2001. -- № 5. -- С.~23-25.

% 7.	Мониторинг состояния оборудования систем связи в трубопроводном транспорте нефти / Л.~И.~ Григорьев [и др.] // Автоматизация, телемеханизация и связь в нефтяной промышленности. -- 2007. -- № 5. -- С.~3-8.

% 15.	Исследовано в России~: многопредмет. науч. журн. / Моск. физ.-техн. ин-т. -- Электрон. журн. -- Режим доступа: http://zhumal.mipt. rssi.ru


1. \emph{Itkin, A.} Deep learning calibration of option pricing models: some pitfalls and solutions / A.~Itkin //  (preprint) arXiv:1906.03507v1 [q-fin.CP] 8 Jun 2019.

2. \emph{Osterlee, C.~W.} A neural network-based framework for financial model calibration / S.~Liu, A.~Borovykh, L.~Grzelak, C.~W.~Oosterlee // Journal of Mathematics in Industry. -- 2019. -- № 9(1):9. DOI: 10.1186/s13362-019-0066-7

3. \emph{Huh, J.} Pricing Options with Exponential L\`evy Neural Network / J.~Huh // Expert Systems with Applications. -- 2019. -- № 127. DOI: 10.1016/j.eswa.2019.03.008

4. \emph{Hochreiter, S.} Long short-term memory / J.~Schmidhuber S.~Hochreiter // Neural \\ Computation. -- 1997. -- № 9(8). --P.~1735-1780. DOI:10.1162/neco.1997.9.8.1735.
	
5. \emph{Carr, P.} The fine structure of asset returns: An empirical investigation / P.~Carr, H.~Geman, D.~Madan, M.~Yor. // The Journal of Business. -- 2002. -- №  75(2) -- P.~305–333.
			
6. \emph{Kudryavtsev, O.} Statistical methods for calibrating models of cryptocurrencies prices / O.~Kudryavtsev, S.~Grechko // Accounting and Statistics. --2018. --№ 4(52). --P.~67-76. ISSN 194-0874.

7. \emph{Horvath, B.} Deep learning volatility a deep neural network perspective
	on pricing and calibration in (rough) volatility models // B.~Horvath, A.~Muguruza, M.~Tomas / SSRN Electronic Journal. --2019. av.~at. http://dx.doi.org/10.2139/ssrn.3322085 
	
8. \emph{Madan, D.~B.} Machine Learning for Quantitative Finance:
Fast Derivative Pricing, Hedging and Fitting // J. De Spiegeleer, D.~B Madan, S.~Reyners, W.~Schoutens / Quantitative Finance. -- 2018. -- № 18(10) -- P.~1-9. DOI: 10.1080/14697688.2018.1495335

9. \emph{Bishop, C.~M.} Neural Networks for Pattern Recognition. // C.~M.~Bishop / Oxford University Press. Inc. -- New York, 1995.
NY, USA.

10. \emph{Kim,~T.}  Forecasting stock prices with a feature fusion LSTM-CNN model using different representations of the same data. // H.~Y.~Kim, T.~Kim / PLoS ONE. -- 2019. -- №14(2), DOI: https://doi.org/10.1371/journal.pone.0212320

11. \emph{Hornik,~K.}  Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks // K.~Hornik, M.~Stinchcombe, H.~White / Neural Networks. -- 1990. -- №3. -- P. 551–560.

12. \emph{Black, F.} The pricing of options and corporate liabilities / F.~Black, M.~Scholes // Journal of Political Economy. -- 1973. -- № 81(3) -- P.~637--654.
\setcounter{equation}{0}
\newpage
%\section{Об авторах}
%%В конце статьи необходимо указать информацию об авторах научной статьи:
%
%%1. Ф.И.О. полностью;
%%2. Ученая степень, звание (если есть);
%%3. Должность (например, доцент кафедры информационных технологий)
%%4. Место работы;
%%5. E-mail;
%%6. Контактный телефон.
%
%1. Ф.И.О. полностью: Кудрявцев Олег Евгеньевич; \\
%2. Ученая степень, звание (если есть): доктор физико-математических наук, доцент; \\
%3. Должность: заведующий кафедрой информатики и информационных таможенных технологий; \\
%4. Место работы: Ростовский филиал Российской Таможенной Академии; \\
%5. E-mail:okudr@mail.ru; \\
%6. Контактный телефон: +7(903)-473-43-95 \\
%1. Ф.И.О. полностью: Родоченко Василий Владимирович;\\
%2. Ученая степень, звание (если есть): нет;         \\
%3. Должность: аспирант;                             \\
%4. Место работы: Южный Федеральный Университет;     \\
%5. E-mail: vrodochenko@gmail.com;                   \\
%6. Контактный телефон: +7(904)-504-11-18            \\

\end{document}

